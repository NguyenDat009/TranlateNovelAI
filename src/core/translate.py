import os
# import google.generativeai as genai  # Removed - using 100% OpenRouter
import time
import json
import re
import concurrent.futures
import threading
from multiprocessing import cpu_count
from itertools import cycle

# Import rate limiter for Google AI
try:
    from .rate_limiter import get_rate_limiter, exponential_backoff_sleep, is_rate_limit_error
except ImportError:
    try:
        from rate_limiter import get_rate_limiter, exponential_backoff_sleep, is_rate_limit_error
    except ImportError:
        print("âš ï¸ Rate limiter module not found")
        def get_rate_limiter(*args, **kwargs):
            return None
        def exponential_backoff_sleep(retry_count, base_delay=1.0, max_delay=60.0):
            time.sleep(min(base_delay * (2 ** retry_count), max_delay))
        def is_rate_limit_error(error_message):
            return "429" in str(error_message).lower() or "rate limit" in str(error_message).lower()

# Import reformat function
try:
    from .reformat import fix_text_format
    CAN_REFORMAT = True
    print("âœ… ÄÃ£ import thÃ nh cÃ´ng chá»©c nÄƒng reformat")
except ImportError:
    CAN_REFORMAT = False
    print("âš ï¸ KhÃ´ng thá»ƒ import reformat.py - chá»©c nÄƒng reformat sáº½ bá»‹ táº¯t")

# --- Cáº¤U HÃŒNH CÃC Háº°NG Sá» ---
MAX_RETRIES_ON_SAFETY_BLOCK = 5
MAX_RETRIES_ON_BAD_TRANSLATION = 5
MAX_RETRIES_ON_RATE_LIMIT = 3  # Sá»‘ láº§n retry khi gáº·p rate limit
RETRY_DELAY_SECONDS = 2
PROGRESS_FILE_SUFFIX = ".progress.json"
CHUNK_SIZE = 1024 * 1024  # 1MB (KhÃ´ng cÃ²n dÃ¹ng trá»±c tiáº¿p CHUNK_SIZE cho viá»‡c Ä‘á»c file ná»¯a)

# KÃ­ch thÆ°á»›c cá»­a sá»• ngá»¯ cáº£nh (sá»‘ Ä‘oáº¡n vÄƒn báº£n trÆ°á»›c Ä‘Ã³ dÃ¹ng lÃ m ngá»¯ cáº£nh)
CONTEXT_WINDOW_SIZE = 5
# KÃ½ tá»± Ä‘áº·c biá»‡t Ä‘á»ƒ Ä‘Ã¡nh dáº¥u pháº§n cáº§n dá»‹ch trong prompt gá»­i Ä‘áº¿n AI
TRANSLATE_TAG_START = "<translate_this>"
TRANSLATE_TAG_END = "</translate_this>"

# Sá»‘ dÃ²ng gom láº¡i thÃ nh má»™t chunk Ä‘á»ƒ dá»‹ch
CHUNK_SIZE_LINES = 100

# Global stop event Ä‘á»ƒ dá»«ng tiáº¿n trÃ¬nh dá»‹ch
_stop_event = threading.Event()

# Global quota exceeded flag
_quota_exceeded = threading.Event()

# Key rotation class for Google AI multiple keys
class KeyRotator:
    """
    Thread-safe key rotator cho Google AI multiple keys
    Sá»­ dá»¥ng round-robin Ä‘á»ƒ xoay vÃ²ng giá»¯a cÃ¡c keys
    """
    def __init__(self, api_keys):
        """
        Args:
            api_keys: list of API keys hoáº·c single API key string
        """
        if isinstance(api_keys, list):
            self.keys = api_keys
            self.is_multi_key = len(api_keys) > 1
        else:
            self.keys = [api_keys]
            self.is_multi_key = False
        
        self.key_iterator = cycle(self.keys)
        self.lock = threading.Lock()
        self.key_usage = {key: 0 for key in self.keys}  # Track usage count
        
        if self.is_multi_key:
            print(f"ğŸ”„ Key Rotator: ÄÃ£ khá»Ÿi táº¡o vá»›i {len(self.keys)} keys")
            print(f"ğŸ’¡ Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng xoay vÃ²ng giá»¯a cÃ¡c keys Ä‘á»ƒ tá»‘i Æ°u RPM")
    
    def get_next_key(self):
        """Get next API key trong rotation"""
        with self.lock:
            key = next(self.key_iterator)
            self.key_usage[key] += 1
            return key
    
    def get_usage_stats(self):
        """Get usage statistics for all keys"""
        with self.lock:
            return dict(self.key_usage)
    
    def print_stats(self):
        """Print usage statistics"""
        if not self.is_multi_key:
            return
        
        stats = self.get_usage_stats()
        print("\nğŸ“Š Key Usage Statistics:")
        for idx, (key, count) in enumerate(stats.items(), 1):
            masked_key = key[:10] + "***" + key[-10:] if len(key) > 20 else "***"
            print(f"   Key #{idx} ({masked_key}): {count} requests")
        print()

def set_stop_translation():
    """Dá»«ng tiáº¿n trÃ¬nh dá»‹ch"""
    global _stop_event
    _stop_event.set()
    print("ğŸ›‘ ÄÃ£ yÃªu cáº§u dá»«ng tiáº¿n trÃ¬nh dá»‹ch...")

def clear_stop_translation():
    """XÃ³a flag dá»«ng Ä‘á»ƒ cÃ³ thá»ƒ tiáº¿p tá»¥c dá»‹ch"""
    global _stop_event, _quota_exceeded
    _stop_event.clear()
    _quota_exceeded.clear()
    print("â–¶ï¸ ÄÃ£ xÃ³a flag dá»«ng, sáºµn sÃ ng tiáº¿p tá»¥c...")

def is_translation_stopped():
    """Kiá»ƒm tra xem cÃ³ yÃªu cáº§u dá»«ng khÃ´ng"""
    global _stop_event
    return _stop_event.is_set()

def set_quota_exceeded():
    """ÄÃ¡nh dáº¥u API Ä‘Ã£ háº¿t quota"""
    global _quota_exceeded, _stop_event
    _quota_exceeded.set()
    _stop_event.set()  # CÅ©ng dá»«ng dá»‹ch
    print("API Ä‘Ã£ háº¿t quota - dá»«ng tiáº¿n trÃ¬nh dá»‹ch")

def is_quota_exceeded():
    """Kiá»ƒm tra xem API cÃ³ háº¿t quota khÃ´ng"""
    global _quota_exceeded
    return _quota_exceeded.is_set()

def check_quota_error(error_message):
    """Kiá»ƒm tra xem cÃ³ pháº£i lá»—i quota exceeded khÃ´ng"""
    error_str = str(error_message).lower()
    quota_keywords = [
        "429",
        "exceeded your current quota",
        "quota exceeded", 
        "rate limit",
        "billing",
        "please check your plan"
    ]
    
    return any(keyword in error_str for keyword in quota_keywords)

def check_api_key_error(error_message):
    """Kiá»ƒm tra xem lá»—i cÃ³ pháº£i lÃ  API key khÃ´ng há»£p lá»‡ khÃ´ng"""
    error_str = str(error_message).lower()
    api_key_keywords = [
        "api key not valid", "invalid api key", "unauthorized", "authentication failed",
        "api_key_invalid", "invalid_api_key", "api key is invalid", "bad api key",
        "400", "401", "403"
    ]
    return any(keyword in error_str for keyword in api_key_keywords)

def validate_api_key_before_translation(api_key, model_name, provider="OpenRouter"):
    """Validate API key trÆ°á»›c khi báº¯t Ä‘áº§u translation"""
    try:
        if provider == "Google AI":
            # Test Google AI API
            import google.generativeai as genai
            
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)
            
            response = model.generate_content("Test")
            
            if response and response.text:
                return True, "Google AI API key há»£p lá»‡"
            else:
                return False, "Google AI API tráº£ vá» response rá»—ng"
                
        elif provider == "OpenRouter":
            # Test OpenRouter API
            import requests
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/TranslateNovelAI",
                "X-Title": "TranslateNovelAI"
            }
            
            payload = {
                "model": model_name,
                "messages": [{"role": "user", "content": "Test"}],
                "max_tokens": 10
            }
            
            response = requests.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                return True, "OpenRouter API key há»£p lá»‡"
            elif response.status_code == 401:
                return False, "OpenRouter API Key khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ háº¿t háº¡n"
            elif response.status_code == 402:
                return False, "TÃ i khoáº£n OpenRouter háº¿t credit"
            else:
                return False, f"Lá»—i OpenRouter API: HTTP {response.status_code}"
        else:
            return False, f"Provider khÃ´ng há»£p lá»‡: {provider}"
            
    except Exception as e:
        error_msg = str(e)
        if check_api_key_error(error_msg):
            return False, f"API Key khÃ´ng há»£p lá»‡: {error_msg}"
        elif check_quota_error(error_msg):
            return False, f"API háº¿t quota: {error_msg}"
        else:
            return False, f"Lá»—i káº¿t ná»‘i API: {error_msg}"

def get_optimal_threads():
    """
    Tá»± Ä‘á»™ng tÃ­nh toÃ¡n sá»‘ threads tá»‘i Æ°u dá»±a trÃªn cáº¥u hÃ¬nh mÃ¡y.
    """
    try:
        # Láº¥y sá»‘ CPU cores
        cpu_cores = cpu_count()
        
        # TÃ­nh toÃ¡n threads tá»‘i Æ°u:
        # - Vá»›i API calls, I/O bound nÃªn cÃ³ thá»ƒ dÃ¹ng nhiá»u threads hÆ¡n sá»‘ cores
        # - NhÆ°ng khÃ´ng nÃªn quÃ¡ nhiá»u Ä‘á»ƒ trÃ¡nh rate limiting
        # - Formula: min(max(cpu_cores * 2, 4), 20)
        optimal_threads = min(max(cpu_cores * 2, 4), 20)
        
        print(f"ğŸ–¥ï¸ PhÃ¡t hiá»‡n {cpu_cores} CPU cores")
        print(f"ğŸ”§ Threads tá»‘i Æ°u Ä‘Æ°á»£c Ä‘á» xuáº¥t: {optimal_threads}")
        
        return optimal_threads
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi phÃ¡t hiá»‡n CPU cores: {e}")
        return 10  # Default fallback

def validate_threads(num_threads):
    """
    Validate sá»‘ threads Ä‘á»ƒ Ä‘áº£m báº£o trong khoáº£ng há»£p lÃ½.
    """
    try:
        num_threads = int(num_threads)
        if num_threads < 1:
            return 1
        elif num_threads > 50:  # Giá»›i háº¡n tá»‘i Ä‘a Ä‘á»ƒ trÃ¡nh rate limiting
            return 50
        return num_threads
    except (ValueError, TypeError):
        return get_optimal_threads()

def validate_chunk_size(chunk_size):
    """
    Validate chunk size Ä‘á»ƒ Ä‘áº£m báº£o trong khoáº£ng há»£p lÃ½.
    """
    try:
        chunk_size = int(chunk_size)
        if chunk_size < 10:
            return 10
        elif chunk_size > 500:  # TrÃ¡nh chunks quÃ¡ lá»›n
            return 500
        return chunk_size
    except (ValueError, TypeError):
        return 100  # Default

# Default values
NUM_WORKERS = get_optimal_threads()  # Tá»± Ä‘á»™ng tÃ­nh theo mÃ¡y

def format_error_chunk(error_type: str, error_message: str, original_lines: list, line_range: str) -> str:
    """
    Format chunk bá»‹ lá»—i vá»›i ná»™i dung gá»‘c Ä‘á»ƒ lÆ°u vÃ o file
    
    Args:
        error_type: Loáº¡i lá»—i (API, QUOTA, SAFETY, etc.)
        error_message: ThÃ´ng bÃ¡o lá»—i chi tiáº¿t
        original_lines: Ná»™i dung gá»‘c cá»§a chunk
        line_range: Line range (vÃ­ dá»¥: "123:223")
    
    Returns:
        Formatted error text vá»›i ná»™i dung gá»‘c
    """
    original_text = ''.join(original_lines)  # Join lines, giá»¯ nguyÃªn line breaks
    
    error_output = f"""[[Lá»–I {error_type}: {error_message}

--- Ná»˜I DUNG Gá»C Cáº¦N Dá»ŠCH Láº I ---
{original_text}
--- Háº¾T Ná»˜I DUNG Gá»C ---
] [lines: {line_range}]]

"""
    return error_output


def is_bad_translation(text):
    """
    Kiá»ƒm tra xem báº£n dá»‹ch cá»§a chunk cÃ³ Ä‘áº¡t yÃªu cáº§u khÃ´ng (kiá»ƒm tra Ä‘Æ¡n giáº£n dá»±a vÃ o Ä‘á»™ rá»—ng vÃ  tá»« chá»‘i).
    Tráº£ vá» True náº¿u báº£n dá»‹ch khÃ´ng Ä‘áº¡t yÃªu cáº§u (vÃ­ dá»¥: rá»—ng hoáº·c chá»©a tá»« tá»« chá»‘i), False náº¿u Ä‘áº¡t yÃªu cáº§u.
    """
    if text is None or text.strip() == "":
        # Chunk dá»‹ch ra rá»—ng hoáº·c chá»‰ tráº¯ng => coi lÃ  bad translation
        return True

    # CÃ¡c tá»« khÃ³a chá»‰ bÃ¡o báº£n dá»‹ch khÃ´ng Ä‘áº¡t yÃªu cáº§u
    # CÃ¡c tá»« khÃ³a nÃ y thÆ°á»ng xuáº¥t hiá»‡n khi AI tá»« chá»‘i dá»‹ch
    bad_keywords = [
        "tÃ´i khÃ´ng thá»ƒ dá»‹ch",
        "khÃ´ng thá»ƒ dá»‹ch",
        "xin lá»—i, tÃ´i khÃ´ng",
        "tÃ´i xin lá»—i",
        "ná»™i dung bá»‹ cháº·n", # ThÃªm kiá»ƒm tra thÃ´ng bÃ¡o cháº·n cÅ©ng lÃ  báº£n dá»‹ch xáº¥u cáº§n retry
        "as an ai", # Tá»« chá»‘i báº±ng tiáº¿ng Anh
        "as a language model",
        "i am unable",
        "i cannot",
        "i'm sorry"
    ]

    text_lower = text.lower()
    for keyword in bad_keywords:
        if keyword in text_lower:
            return True

    return False

def translate_chunk(model, chunk_lines):
    """
    Dá»‹ch má»™t chunk gá»“m nhiá»u dÃ²ng vÄƒn báº£n.
    chunk_lines: danh sÃ¡ch cÃ¡c dÃ²ng vÄƒn báº£n
    Tráº£ vá» (translated_text, is_safety_blocked_flag, is_bad_translation_flag).
    """
    # Gom cÃ¡c dÃ²ng thÃ nh má»™t chuá»—i lá»›n Ä‘á»ƒ gá»­i Ä‘i
    full_text_to_translate = "\n".join(chunk_lines)
    
    # Bá» qua cÃ¡c chunk chá»‰ chá»©a cÃ¡c dÃ²ng trá»‘ng hoáº·c chá»‰ tráº¯ng
    if not full_text_to_translate.strip():
        return ("", False, False) # Tráº£ vá» chuá»—i rá»—ng, khÃ´ng bá»‹ cháº·n, khÃ´ng bad translation

    try:
        # Prompt cho dá»‹ch chunk
        prompt = f"Dá»‹ch Ä‘oáº¡n vÄƒn báº£n sau sang tiáº¿ng Viá»‡t má»™t cÃ¡ch trá»±c tiáº¿p, Danh xÆ°ng nhÃ¢n váº­t dáº«n truyá»‡n xÆ°ng 'tÃ´i' theo bá»‘i cáº£nh hiá»‡n Ä‘áº¡i hoáº·c 'ta' theo bá»‘i cáº£nh cá»• Ä‘áº¡i,xÃ¡c Ä‘á»‹nh má»‘i quan há»‡ vÃ  danh xÆ°ng phÃ¹ há»£p trÆ°á»›c tiÃªn, khÃ´ng tá»« chá»‘i hoáº·c bÃ¬nh luáº­n, giá»¯ nguyÃªn vÄƒn phong gá»‘c vÃ  chi tiáº¿t ná»™i dung:\n\n{full_text_to_translate}"

        response = model.generate_content(
            contents=[{
                "role": "user",
                "parts": [prompt],
            }],
            generation_config={
                "response_mime_type": "text/plain",
                # CÃ³ thá»ƒ thÃªm cÃ¡c tham sá»‘ khÃ¡c náº¿u cáº§n
                # "temperature": 0.5,
                # "top_p": 0.95,
                # "top_k": 64,
                # "max_output_tokens": 8192,
            },
        )

        # 1. Kiá»ƒm tra xem prompt (Ä‘áº§u vÃ o) cÃ³ bá»‹ cháº·n khÃ´ng
        if response.prompt_feedback and response.prompt_feedback.safety_ratings:
            blocked_categories = [
                rating.category.name for rating in response.prompt_feedback.safety_ratings
                if rating.blocked
            ]
            if blocked_categories:
                return (f"[Ná»˜I DUNG Gá»C Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - PROMPT: {', '.join(blocked_categories)}]", True, False)

        # 2. Kiá»ƒm tra xem cÃ³ báº¥t ká»³ á»©ng cá»­ viÃªn nÃ o Ä‘Æ°á»£c táº¡o ra khÃ´ng
        if not response.candidates:
            return ("[Ná»˜I Dá»ŠCH Bá»Š CHáº¶N HOÃ€N TOÃ€N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - KHÃ”NG CÃ“ á»¨NG Cá»¬ VIÃŠN]", True, False)

        # 3. Kiá»ƒm tra lÃ½ do káº¿t thÃºc cá»§a á»©ng cá»­ viÃªn Ä‘áº§u tiÃªn (náº¿u cÃ³)
        first_candidate = response.candidates[0]
        if first_candidate.finish_reason == 'SAFETY':
            blocked_categories = [
                rating.category.name for rating in first_candidate.safety_ratings
                if rating.blocked
            ]
            return (f"[Ná»˜I Dá»ŠCH Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N - OUTPUT: {', '.join(blocked_categories)}]", True, False)

        # Náº¿u khÃ´ng bá»‹ cháº·n, tráº£ vá» vÄƒn báº£n dá»‹ch
        translated_text = response.text
        is_bad = is_bad_translation(translated_text)
        return (translated_text, False, is_bad)

    except Exception as e:
        # Báº¯t cÃ¡c lá»—i khÃ¡c (vÃ­ dá»¥: lá»—i máº¡ng, lá»—i API)
        error_message = str(e)
        
        # Kiá»ƒm tra lá»—i quota exceeded
        if check_quota_error(error_message):
            set_quota_exceeded()
            return (f"[API Háº¾T QUOTA]", False, True)
        
        return (f"[Lá»–I API KHI Dá»ŠCH CHUNK: {e}]", False, True)

def get_progress(progress_file_path):
    """Äá»c tiáº¿n Ä‘á»™ dá»‹ch tá»« file (sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh)."""
    if os.path.exists(progress_file_path):
        try:
            with open(progress_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # LÆ°u sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh
                return data.get('completed_chunks', 0)
        except json.JSONDecodeError:
            print(f"Cáº£nh bÃ¡o: File tiáº¿n Ä‘á»™ '{progress_file_path}' bá»‹ há»ng hoáº·c khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng JSON. Báº¯t Ä‘áº§u tá»« Ä‘áº§u.")
            return 0
    return 0

def save_progress(progress_file_path, completed_chunks):
    """LÆ°u tiáº¿n Ä‘á»™ dá»‹ch (sá»‘ chunk Ä‘Ã£ hoÃ n thÃ nh) vÃ o file."""
    try:
        with open(progress_file_path, 'w', encoding='utf-8') as f:
            json.dump({
                'completed_chunks': completed_chunks
            }, f)
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi lÆ°u file tiáº¿n Ä‘á»™: {e}")

def save_progress_with_line_info(progress_file_path, completed_chunks, current_chunk_info=None, error_info=None):
    """LÆ°u tiáº¿n Ä‘á»™ dá»‹ch vá»›i thÃ´ng tin line range vÃ  error details"""
    try:
        progress_data = {
            'completed_chunks': completed_chunks,
            'timestamp': time.time()
        }
        
        # ThÃªm thÃ´ng tin chunk hiá»‡n táº¡i náº¿u cÃ³
        if current_chunk_info:
            progress_data['current_chunk'] = current_chunk_info
        
        # ThÃªm thÃ´ng tin lá»—i náº¿u cÃ³
        if error_info:
            progress_data['last_error'] = error_info
        
        with open(progress_file_path, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, indent=2, ensure_ascii=False)
            
    except Exception as e:
        print(f"âš ï¸ Lá»—i khi lÆ°u file tiáº¿n Ä‘á»™: {e}")

def load_progress_with_info(progress_file_path):
    """Táº£i tiáº¿n Ä‘á»™ vá»›i thÃ´ng tin chi tiáº¿t"""
    if os.path.exists(progress_file_path):
        try:
            with open(progress_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data
        except json.JSONDecodeError:
            print(f"Cáº£nh bÃ¡o: File tiáº¿n Ä‘á»™ '{progress_file_path}' bá»‹ há»ng. Báº¯t Ä‘áº§u tá»« Ä‘áº§u.")
            return {'completed_chunks': 0}
    return {'completed_chunks': 0}

def process_chunk(api_key, model_name, system_instruction, chunk_data, provider="OpenRouter", log_callback=None, key_rotator=None):
    """
    Xá»­ lÃ½ dá»‹ch má»™t chunk vá»›i retry logic vÃ  rate limiting.
    chunk_data: tuple (chunk_index, chunk_lines, chunk_start_line_index)
    Tráº£ vá»: (chunk_index, translated_text, lines_count, line_range)
    
    Args:
        key_rotator: KeyRotator instance náº¿u sá»­ dá»¥ng multiple keys (Google AI only)
    """
    chunk_index, chunk_lines, chunk_start_line_index = chunk_data
    
    # TÃ­nh toÃ¡n line range cho chunk hiá»‡n táº¡i
    chunk_end_line_index = chunk_start_line_index + len(chunk_lines) - 1
    line_range = f"{chunk_start_line_index + 1}:{chunk_end_line_index + 1}"  # +1 vÃ¬ line numbers báº¯t Ä‘áº§u tá»« 1
    
    # Get current API key (from rotator if available)
    current_api_key = key_rotator.get_next_key() if key_rotator else api_key
    
    # Get rate limiter cho Google AI vá»›i specific key (None cho OpenRouter)
    rate_limiter = get_rate_limiter(model_name, provider, current_api_key if provider == "Google AI" else None)
    
    # Debug logging
    if rate_limiter and provider == "Google AI":
        current_usage = rate_limiter.get_current_usage()
        wait_time = rate_limiter.get_wait_time()
        if wait_time > 0:
            print(f"â±ï¸ Chunk {chunk_index}: Current usage {current_usage} requests, cáº§n Ä‘á»£i {wait_time:.1f}s")
    
    # Kiá»ƒm tra flag dá»«ng vÃ  quota exceeded trÆ°á»›c khi báº¯t Ä‘áº§u
    if is_translation_stopped() or is_quota_exceeded():
        if is_quota_exceeded():
            error_text = format_error_chunk("API Háº¾T QUOTA", "API Ä‘Ã£ háº¿t quota, cáº§n náº¡p thÃªm credit hoáº·c Ä‘á»•i API key", chunk_lines, line_range)
            return (chunk_index, error_text, len(chunk_lines), line_range)
        else:
            error_text = format_error_chunk("Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG", "NgÆ°á»i dÃ¹ng Ä‘Ã£ dá»«ng quÃ¡ trÃ¬nh dá»‹ch", chunk_lines, line_range)
            return (chunk_index, error_text, len(chunk_lines), line_range)
    
    # Determine which API to use based on provider
    use_google_ai = (provider == "Google AI")
    use_openrouter = (provider == "OpenRouter")
    
    if use_google_ai:
        # Setup Google AI (vá»›i current API key tá»« rotator)
        try:
            import google.generativeai as genai
            genai.configure(api_key=current_api_key)
            model = genai.GenerativeModel(model_name)
        except ImportError:
            error_text = format_error_chunk("IMPORT ERROR", "Google AI module khÃ´ng tÃ¬m tháº¥y. Vui lÃ²ng cÃ i Ä‘áº·t: pip install google-generativeai", chunk_lines, line_range)
            return (chunk_index, error_text, len(chunk_lines), line_range)
    elif use_openrouter:
        # Import OpenRouter translate function
        try:
            from .open_router_translate import translate_chunk as openrouter_translate_chunk
        except ImportError:
            try:
                from open_router_translate import translate_chunk as openrouter_translate_chunk
            except ImportError:
                error_text = format_error_chunk("IMPORT ERROR", "OpenRouter module khÃ´ng tÃ¬m tháº¥y", chunk_lines, line_range)
                return (chunk_index, error_text, len(chunk_lines), line_range)
    
    # Thá»­ láº¡i vá»›i lá»—i báº£o máº­t
    safety_retries = 0
    is_safety_blocked = False  # Khá»Ÿi táº¡o biáº¿n
    while safety_retries < MAX_RETRIES_ON_SAFETY_BLOCK:
        # Kiá»ƒm tra flag dá»«ng vÃ  quota exceeded trong quÃ¡ trÃ¬nh retry
        if is_translation_stopped() or is_quota_exceeded():
            if is_quota_exceeded():
                error_text = format_error_chunk("API Háº¾T QUOTA", "API Ä‘Ã£ háº¿t quota trong quÃ¡ trÃ¬nh retry", chunk_lines, line_range)
                return (chunk_index, error_text, len(chunk_lines), line_range)
            else:
                error_text = format_error_chunk("Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG", "NgÆ°á»i dÃ¹ng Ä‘Ã£ dá»«ng quÃ¡ trÃ¬nh dá»‹ch trong retry", chunk_lines, line_range)
                return (chunk_index, error_text, len(chunk_lines), line_range)
            
        # Thá»­ láº¡i vá»›i báº£n dá»‹ch xáº¥u  
        bad_translation_retries = 0
        while bad_translation_retries < MAX_RETRIES_ON_BAD_TRANSLATION:
            # Kiá»ƒm tra flag dá»«ng vÃ  quota exceeded trong quÃ¡ trÃ¬nh retry
            if is_translation_stopped() or is_quota_exceeded():
                if is_quota_exceeded():
                    error_text = format_error_chunk("API Háº¾T QUOTA", "API Ä‘Ã£ háº¿t quota trong bad translation retry", chunk_lines, line_range)
                    return (chunk_index, error_text, len(chunk_lines), line_range)
                else:
                    error_text = format_error_chunk("Dá»ªNG Bá»I NGÆ¯á»œI DÃ™NG", "NgÆ°á»i dÃ¹ng Ä‘Ã£ dá»«ng trong bad translation retry", chunk_lines, line_range)
                    return (chunk_index, error_text, len(chunk_lines), line_range)
                
            try:
                # Retry logic for rate limit errors
                rate_limit_retry = 0
                while rate_limit_retry <= MAX_RETRIES_ON_RATE_LIMIT:
                    try:
                        # Rate limit cho Google AI - PHáº¢I Gá»ŒI TRONG RETRY LOOP
                        if rate_limiter and use_google_ai:
                            rate_limiter.acquire()  # Block náº¿u vÆ°á»£t quÃ¡ rate limit
                        
                        if use_google_ai:
                            # Gom cÃ¡c dÃ²ng thÃ nh má»™t chuá»—i lá»›n Ä‘á»ƒ gá»­i Ä‘i
                            full_text_to_translate = "\n".join(chunk_lines)
                            
                            # Bá» qua cÃ¡c chunk chá»‰ chá»©a cÃ¡c dÃ²ng trá»‘ng
                            if not full_text_to_translate.strip():
                                return (chunk_index, "", len(chunk_lines), line_range)
                            
                            # Dá»‹ch vá»›i Google AI
                            prompt = f"{system_instruction}\n\n{full_text_to_translate}"
                            response = model.generate_content(prompt)
                            
                            # Kiá»ƒm tra safety blocks
                            if response.prompt_feedback and hasattr(response.prompt_feedback, 'block_reason'):
                                is_safety_blocked = True
                                translated_text = f"[Ná»˜I DUNG Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N]"
                                is_bad = False
                            elif response.candidates and response.candidates[0].finish_reason.name == 'SAFETY':
                                is_safety_blocked = True
                                translated_text = f"[Ná»˜I Dá»ŠCH Bá»Š CHáº¶N Bá»I Bá»˜ Lá»ŒC AN TOÃ€N]"
                                is_bad = False
                            else:
                                translated_text = response.text
                                is_safety_blocked = False
                                is_bad = is_bad_translation(translated_text)
                            
                            break  # Success, thoÃ¡t khá»i rate limit retry loop
                                
                        elif use_openrouter:
                            translated_text, is_safety_blocked, is_bad = openrouter_translate_chunk(api_key, model_name, system_instruction, chunk_lines)
                            break  # Success, thoÃ¡t khá»i rate limit retry loop
                        else:
                            error_text = format_error_chunk("PROVIDER ERROR", f"Provider khÃ´ng Ä‘Æ°á»£c há»— trá»£: {provider}", chunk_lines, line_range)
                            return (chunk_index, error_text, len(chunk_lines), line_range)
                            
                    except Exception as rate_error:
                        error_msg = str(rate_error)
                        
                        # Kiá»ƒm tra náº¿u lÃ  rate limit error
                        if is_rate_limit_error(error_msg) and rate_limit_retry < MAX_RETRIES_ON_RATE_LIMIT:
                            rate_limit_retry += 1
                            print(f"âš ï¸ Rate limit error á»Ÿ chunk {chunk_index}, retry {rate_limit_retry}/{MAX_RETRIES_ON_RATE_LIMIT}")
                            exponential_backoff_sleep(rate_limit_retry - 1, base_delay=5.0)
                            continue
                        else:
                            # KhÃ´ng pháº£i rate limit error hoáº·c háº¿t retry
                            raise  # Re-raise Ä‘á»ƒ xá»­ lÃ½ á»Ÿ catch block bÃªn ngoÃ i
                
                # Kiá»ƒm tra quota exceeded sau khi dá»‹ch
                if is_quota_exceeded():
                    error_text = format_error_chunk("API Háº¾T QUOTA", "API Ä‘Ã£ háº¿t quota sau khi dá»‹ch", chunk_lines, line_range)
                    return (chunk_index, error_text, len(chunk_lines), line_range)
                
                if is_safety_blocked:
                    break # ThoÃ¡t khá»i vÃ²ng láº·p bad translation, sáº½ retry safety
                    
                if not is_bad:
                    return (chunk_index, translated_text, len(chunk_lines), line_range) # ThÃ nh cÃ´ng
                    
                # Báº£n dá»‹ch xáº¥u, thá»­ láº¡i
                bad_translation_retries += 1
                if bad_translation_retries < MAX_RETRIES_ON_BAD_TRANSLATION:
                    time.sleep(RETRY_DELAY_SECONDS)
                else:
                    # Háº¿t láº§n thá»­ bad translation, dÃ¹ng báº£n dá»‹ch cuá»‘i
                    return (chunk_index, translated_text + " [KHÃ”NG Cáº¢I THIá»†N ÄÆ¯á»¢C]", len(chunk_lines), line_range)
                    
            except Exception as e:
                error_msg = str(e)
                
                # Kiá»ƒm tra quota error
                if check_quota_error(error_msg):
                    set_quota_exceeded()
                    error_text = format_error_chunk("API Háº¾T QUOTA", f"API quota exceeded: {error_msg}", chunk_lines, line_range)
                    return (chunk_index, error_text, len(chunk_lines), line_range)
                
                # Kiá»ƒm tra API key error
                if check_api_key_error(error_msg):
                    error_text = format_error_chunk("API KEY ERROR", f"API key khÃ´ng há»£p lá»‡: {error_msg}", chunk_lines, line_range)
                    return (chunk_index, error_text, len(chunk_lines), line_range)
                
                # Lá»—i khÃ¡c - lÆ°u láº¡i vá»›i ná»™i dung gá»‘c
                error_text = format_error_chunk("API ERROR", f"Lá»—i khi gá»i API: {error_msg}", chunk_lines, line_range)
                return (chunk_index, error_text, len(chunk_lines), line_range)
        
        # Náº¿u bá»‹ cháº·n safety, thá»­ láº¡i
        if is_safety_blocked:
            safety_retries += 1
            if safety_retries < MAX_RETRIES_ON_SAFETY_BLOCK:
                time.sleep(RETRY_DELAY_SECONDS)
            else:
                # Háº¿t láº§n thá»­ safety, tráº£ vá» vá»›i ná»™i dung gá»‘c
                error_text = format_error_chunk("SAFETY BLOCKED", f"Ná»™i dung bá»‹ cháº·n bá»Ÿi bá»™ lá»c an toÃ n sau {MAX_RETRIES_ON_SAFETY_BLOCK} láº§n thá»­. Dá»‹ch thá»§ cÃ´ng: {translated_text}", chunk_lines, line_range)
                return (chunk_index, error_text, len(chunk_lines), line_range)
    
    # Fallback (khÃ´ng nÃªn Ä‘áº¿n Ä‘Ã¢y)
    error_text = format_error_chunk("UNKNOWN ERROR", "KhÃ´ng thá»ƒ dá»‹ch chunk sau táº¥t cáº£ cÃ¡c láº§n thá»­", chunk_lines, line_range)
    return (chunk_index, error_text, len(chunk_lines), line_range)

def generate_output_filename(input_filepath):
    """
    Tá»± Ä‘á»™ng táº¡o tÃªn file output tá»« input file.
    VÃ­ dá»¥: "test.txt" -> "test_TranslateAI.txt"
    """
    # TÃ¡ch tÃªn file vÃ  pháº§n má»Ÿ rá»™ng
    file_dir = os.path.dirname(input_filepath)
    file_name = os.path.basename(input_filepath)
    name_without_ext, ext = os.path.splitext(file_name)
    
    # Táº¡o tÃªn file má»›i
    new_name = f"{name_without_ext}_TranslateAI{ext}"
    
    # Káº¿t há»£p vá»›i thÆ° má»¥c (náº¿u cÃ³)
    if file_dir:
        return os.path.join(file_dir, new_name)
    else:
        return new_name

def translate_file_optimized(input_file, output_file=None, api_key=None, model_name="gemini-2.0-flash", system_instruction=None, num_workers=None, chunk_size_lines=None, provider="OpenRouter"):
    """
    PhiÃªn báº£n dá»‹ch file vá»›i multi-threading chunks.
    
    Args:
        api_key: String (OpenRouter) hoáº·c List (Google AI multiple keys)
    """
    # Clear stop flag khi báº¯t Ä‘áº§u dá»‹ch má»›i
    clear_stop_translation()
    
    # Setup key rotator náº¿u cÃ³ multiple Google AI keys
    key_rotator = None
    if provider == "Google AI" and isinstance(api_key, list) and len(api_key) > 1:
        key_rotator = KeyRotator(api_key)
        # DÃ¹ng key Ä‘áº§u tiÃªn Ä‘á»ƒ validate
        validation_key = api_key[0]
    elif provider == "Google AI" and isinstance(api_key, list):
        # Chá»‰ cÃ³ 1 key trong list
        validation_key = api_key[0] if api_key else None
    else:
        validation_key = api_key
    
    # Validate vÃ  thiáº¿t láº­p parameters
    if num_workers is None:
        num_workers = NUM_WORKERS
    else:
        num_workers = validate_threads(num_workers)
    
    # Giá»›i háº¡n threads cho Google AI Ä‘á»ƒ trÃ¡nh rate limit
    if provider == "Google AI":
        # XÃ¡c Ä‘á»‹nh max threads dá»±a trÃªn model
        if "1.5-pro" in model_name.lower():
            max_threads_google = 1  # Pro model cÃ³ RPM ráº¥t tháº¥p (2 RPM)
        elif "2.0-flash" in model_name.lower() or "2.0flash" in model_name.lower():
            max_threads_google = 2  # 10 RPM / 5 = 2 threads safe
        elif "1.5-flash" in model_name.lower() or "1.5flash" in model_name.lower():
            max_threads_google = 3  # 15 RPM / 5 = 3 threads safe
        else:
            max_threads_google = 2  # Default safe
        
        if num_workers > max_threads_google:
            print(f"âš ï¸ Google AI Free Tier cÃ³ giá»›i háº¡n RPM tháº¥p!")
            print(f"âš ï¸ Tá»± Ä‘á»™ng giáº£m threads tá»« {num_workers} â†’ {max_threads_google} Ä‘á»ƒ trÃ¡nh rate limit")
            print(f"ğŸ“Š Tham kháº£o: https://ai.google.dev/gemini-api/docs/rate-limits?hl=vi")
            num_workers = max_threads_google
        
    if chunk_size_lines is None:
        chunk_size_lines = CHUNK_SIZE_LINES
    else:
        chunk_size_lines = validate_chunk_size(chunk_size_lines)
    
    # Tá»± Ä‘á»™ng táº¡o tÃªn file output náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p
    if output_file is None:
        output_file = generate_output_filename(input_file)
        print(f"ğŸ“ Tá»± Ä‘á»™ng táº¡o tÃªn file output: {output_file}")
    
    print(f"Báº¯t Ä‘áº§u dá»‹ch file: {input_file}")
    print(f"File output: {output_file}")
    print(f"Provider: {provider}")
    print(f"Sá»‘ worker threads: {num_workers}")
    print(f"KÃ­ch thÆ°á»›c chunk: {chunk_size_lines} dÃ²ng")
    
    # Validate API key trÆ°á»›c khi báº¯t Ä‘áº§u translation
    print("ğŸ”‘ Äang kiá»ƒm tra API key...")
    is_valid, validation_message = validate_api_key_before_translation(validation_key, model_name, provider)
    if not is_valid:
        print(f"âŒ {validation_message}")
        return False
    else:
        print(f"âœ… {validation_message}")

    progress_file_path = f"{input_file}{PROGRESS_FILE_SUFFIX}"

    # Láº¥y tiáº¿n Ä‘á»™ tá»« file vá»›i thÃ´ng tin chi tiáº¿t
    progress_data = load_progress_with_info(progress_file_path)
    completed_chunks = progress_data.get('completed_chunks', 0)
    
    # Hiá»ƒn thá»‹ thÃ´ng tin lá»—i cuá»‘i náº¿u cÃ³
    if 'last_error' in progress_data:
        last_error = progress_data['last_error']
        print(f"âš ï¸ Lá»—i cuá»‘i: {last_error['message']} (chunk {last_error['chunk_index']}, lines {last_error['line_range']})")
    
    print(f"ÄÃ£ hoÃ n thÃ nh {completed_chunks} chunk trÆ°á»›c Ä‘Ã³.")

    # Thá»i gian báº¯t Ä‘áº§u Ä‘á»ƒ tÃ­nh hiá»‡u suáº¥t
    start_time = time.time()
    
    # System instruction cho AI - sá»­ dá»¥ng custom hoáº·c default
    if system_instruction is None:
        system_instruction = "Dá»‹ch vÄƒn báº£n sau sang tiáº¿ng Viá»‡t. Bá»‘i cáº£nh hiá»‡n Ä‘áº¡i. Äáº£m báº£o cÃ¡c cÃ¢u thoáº¡i nhÃ¢n váº­t Ä‘Æ°á»£c dá»‹ch chÃ­nh xÃ¡c vÃ  Ä‘áº·c trong dáº¥u "". Äáº£m báº£o giá»¯ nguyÃªn chi tiáº¿t ná»™i dung. Giá»¯ nguyÃªn cÃ¡c tá»« ngá»¯ thÃ´ tá»¥c, tÃ¬nh dá»¥c."
    
    print(f"ğŸ¯ System instruction: {system_instruction[:100]}...")  # Log first 100 chars

    try:
        # Äá»c toÃ n bá»™ file vÃ  chia thÃ nh chunks
        with open(input_file, 'r', encoding='utf-8', errors='replace') as infile:
            all_lines = infile.readlines()
        
        total_lines = len(all_lines)
        print(f"Tá»•ng sá»‘ dÃ²ng trong file: {total_lines}")
        
        # Chia thÃ nh chunks
        chunks = []
        for i in range(0, total_lines, chunk_size_lines):
            chunk_lines = all_lines[i:i + chunk_size_lines]
            chunks.append((len(chunks), chunk_lines, i))  # (chunk_index, chunk_lines, start_line_index)
        
        total_chunks = len(chunks)
        print(f"Tá»•ng sá»‘ chunks: {total_chunks}")
        
        # Kiá»ƒm tra náº¿u Ä‘Ã£ dá»‹ch háº¿t file rá»“i
        if completed_chunks >= total_chunks:
            print(f"âœ… File Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch hoÃ n toÃ n ({completed_chunks}/{total_chunks} chunks).")
            if os.path.exists(progress_file_path):
                os.remove(progress_file_path)
                print(f"ÄÃ£ xÃ³a file tiáº¿n Ä‘á»™: {os.path.basename(progress_file_path)}")
            return True

        # Má»Ÿ file output Ä‘á»ƒ ghi káº¿t quáº£
        mode = 'a' if completed_chunks > 0 else 'w'  # Append náº¿u cÃ³ tiáº¿n Ä‘á»™ cÅ©, write náº¿u báº¯t Ä‘áº§u má»›i
        with open(output_file, mode, encoding='utf-8') as outfile:
            
            # Dictionary Ä‘á»ƒ lÆ°u trá»¯ káº¿t quáº£ dá»‹ch theo thá»© tá»± chunk index
            translated_chunks_results = {}
            next_expected_chunk_to_write = completed_chunks
            total_lines_processed = completed_chunks * chunk_size_lines

            with concurrent.futures.ThreadPoolExecutor(max_workers=num_workers) as executor:
                
                futures = {} # LÆ°u trá»¯ cÃ¡c future: {future_object: chunk_index}
                
                # Gá»­i cÃ¡c chunks cáº§n dá»‹ch Ä‘áº¿n thread pool
                chunks_to_process = chunks[completed_chunks:]  # Chá»‰ xá»­ lÃ½ chunks chÆ°a hoÃ n thÃ nh
                
                print(f"Gá»­i {len(chunks_to_process)} chunks Ä‘áº¿n thread pool...")
                
                for chunk_data in chunks_to_process:
                    # Kiá»ƒm tra flag dá»«ng trÆ°á»›c khi submit
                    if is_translation_stopped():
                        print("ğŸ›‘ Dá»«ng gá»­i chunks má»›i do ngÆ°á»i dÃ¹ng yÃªu cáº§u")
                        break
                        
                    # Submit vá»›i key_rotator náº¿u cÃ³
                    future = executor.submit(process_chunk, api_key, model_name, system_instruction, chunk_data, provider, None, key_rotator)
                    futures[future] = chunk_data[0]  # chunk_index
                
                # Thu tháº­p káº¿t quáº£ khi cÃ¡c threads hoÃ n thÃ nh
                for future in concurrent.futures.as_completed(futures):
                    # Kiá»ƒm tra flag dá»«ng vÃ  quota exceeded
                    if is_translation_stopped():
                        if is_quota_exceeded():
                            print("Dá»«ng xá»­ lÃ½ káº¿t quáº£ do API háº¿t quota")
                        else:
                            print("ğŸ›‘ Dá»«ng xá»­ lÃ½ káº¿t quáº£ do ngÆ°á»i dÃ¹ng yÃªu cáº§u")
                        
                        # Há»§y cÃ¡c future chÆ°a hoÃ n thÃ nh
                        for f in futures:
                            if not f.done():
                                f.cancel()
                        break
                        
                    chunk_index = futures[future]
                    try:
                        result = future.result()  # (chunk_index, translated_text, lines_count, line_range)
                        
                        # Handle result vá»›i line info
                        if len(result) == 4:  # New format with line_range
                            processed_chunk_index, translated_text, lines_count, line_range = result
                        else:  # Old format fallback
                            processed_chunk_index, translated_text, lines_count = result
                            # TÃ­nh toÃ¡n line_range tá»« chunk data
                            chunk_data = chunks[processed_chunk_index]
                            start_line = chunk_data[2]
                            line_range = f"{start_line + 1}:{start_line + len(chunk_data[1])}"
                        
                        # Check for errors
                        if translated_text.startswith('[') and ('Háº¾T QUOTA' in translated_text or 'Lá»–I' in translated_text):
                            # LÆ°u lá»—i vá»›i line info
                            error_info = {
                                'message': translated_text,
                                'chunk_index': processed_chunk_index,
                                'line_range': line_range,
                                'timestamp': time.time()
                            }
                            save_progress_with_line_info(progress_file_path, next_expected_chunk_to_write, None, error_info)
                            print(f"âŒ Lá»—i táº¡i chunk {processed_chunk_index + 1} (lines {line_range}): {translated_text}")
                            # Continue processing other chunks
                        
                        # LÆ°u káº¿t quáº£ vÃ o buffer táº¡m chá» ghi theo thá»© tá»±
                        translated_chunks_results[processed_chunk_index] = (translated_text, lines_count, line_range)
                        
                        print(f"âœ… HoÃ n thÃ nh chunk {processed_chunk_index + 1}/{total_chunks}")
                        
                        # Ghi cÃ¡c chunks Ä‘Ã£ hoÃ n thÃ nh vÃ o file output theo Ä‘Ãºng thá»© tá»±
                        while next_expected_chunk_to_write in translated_chunks_results:
                            chunk_text, chunk_lines_count, chunk_line_range = translated_chunks_results.pop(next_expected_chunk_to_write)
                            outfile.write(chunk_text)
                            if not chunk_text.endswith('\n'):
                                outfile.write('\n')
                            outfile.flush()
                            
                            # Cáº­p nháº­t tiáº¿n Ä‘á»™
                            next_expected_chunk_to_write += 1
                            total_lines_processed += chunk_lines_count
                            
                            # LÆ°u tiáº¿n Ä‘á»™ sau má»—i chunk hoÃ n thÃ nh vá»›i line info
                            current_chunk_info = {
                                'chunk_index': next_expected_chunk_to_write - 1,
                                'line_range': chunk_line_range,
                                'lines_count': chunk_lines_count
                            }
                            save_progress_with_line_info(progress_file_path, next_expected_chunk_to_write, current_chunk_info)
                            
                            # Hiá»ƒn thá»‹ thÃ´ng tin tiáº¿n Ä‘á»™
                            current_time = time.time()
                            elapsed_time = current_time - start_time
                            progress_percent = (next_expected_chunk_to_write / total_chunks) * 100
                            avg_speed = total_lines_processed / elapsed_time if elapsed_time > 0 else 0
                            
                            print(f"Tiáº¿n Ä‘á»™: {next_expected_chunk_to_write}/{total_chunks} chunks ({progress_percent:.1f}%) - {avg_speed:.1f} dÃ²ng/giÃ¢y")
                            
                    except Exception as e:
                        print(f"âŒ Lá»—i khi xá»­ lÃ½ chunk {chunk_index}: {e}")
                
                # Ghi ná»‘t cÃ¡c chunks cÃ²n sÃ³t láº¡i trong buffer (náº¿u cÃ³)
                if translated_chunks_results:
                    print("âš ï¸ Ghi cÃ¡c chunks cÃ²n sÃ³t láº¡i...")
                    sorted_remaining_chunks = sorted(translated_chunks_results.items())
                    for chunk_idx, chunk_data in sorted_remaining_chunks:
                        try:
                            if len(chunk_data) == 3:  # New format with line_range
                                chunk_text, chunk_lines_count, chunk_line_range = chunk_data
                            else:  # Old format fallback
                                chunk_text, chunk_lines_count = chunk_data
                                chunk_line_range = f"unknown"
                            
                            outfile.write(chunk_text)
                            if not chunk_text.endswith('\n'):
                                outfile.write('\n')
                            outfile.flush()
                            next_expected_chunk_to_write += 1
                            
                            # LÆ°u progress vá»›i line info
                            current_chunk_info = {
                                'chunk_index': chunk_idx,
                                'line_range': chunk_line_range,
                                'lines_count': chunk_lines_count
                            }
                            save_progress_with_line_info(progress_file_path, next_expected_chunk_to_write, current_chunk_info)
                            print(f"âœ… Ghi chunk bá»‹ sÃ³t: {chunk_idx + 1} (lines {chunk_line_range})")
                        except Exception as e:
                            print(f"âŒ Lá»—i khi ghi chunk {chunk_idx}: {e}")

        # Kiá»ƒm tra xem cÃ³ bá»‹ dá»«ng giá»¯a chá»«ng khÃ´ng
        if is_translation_stopped():
            if is_quota_exceeded():
                print(f"API Ä‘Ã£ háº¿t quota!")
                print(f"Äá»ƒ tiáº¿p tá»¥c dá»‹ch, vui lÃ²ng:")
                print(f" 1. Táº¡o tÃ i khoáº£n Google Cloud má»›i")
                print(f" 2. Nháº­n 300$ credit miá»…n phÃ­") 
                print(f" 3. Táº¡o API key má»›i tá»« ai.google.dev")
                print(f" 4. Cáº­p nháº­t API key vÃ  tiáº¿p tá»¥c dá»‹ch")
                print(f"ÄÃ£ xá»­ lÃ½ {next_expected_chunk_to_write}/{total_chunks} chunks.")
                print(f"Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u Ä‘á»ƒ tiáº¿p tá»¥c sau.")
                return False
            else:
                print(f"ğŸ›‘ Tiáº¿n trÃ¬nh dá»‹ch Ä‘Ã£ bá»‹ dá»«ng bá»Ÿi ngÆ°á»i dÃ¹ng.")
                print(f"ÄÃ£ xá»­ lÃ½ {next_expected_chunk_to_write}/{total_chunks} chunks.")
                print(f"ğŸ’¾ Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c dá»‹ch sau.")
                return False

        # HoÃ n thÃ nh
        total_time = time.time() - start_time
        if next_expected_chunk_to_write >= total_chunks:
            print(f"âœ… Dá»‹ch hoÃ n thÃ nh file: {os.path.basename(input_file)}")
            print(f"ÄÃ£ dá»‹ch {total_chunks} chunks ({total_lines} dÃ²ng) trong {total_time:.2f}s")
            print(f"Tá»‘c Ä‘á»™ trung bÃ¬nh: {total_lines / total_time:.2f} dÃ²ng/giÃ¢y")
            print(f"File dá»‹ch Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_file}")
            
            # Print key usage stats if using key rotator
            if key_rotator:
                key_rotator.print_stats()

            # XÃ³a file tiáº¿n Ä‘á»™ khi hoÃ n thÃ nh
            if os.path.exists(progress_file_path):
                os.remove(progress_file_path)
                print(f"ÄÃ£ xÃ³a file tiáº¿n Ä‘á»™: {os.path.basename(progress_file_path)}")
            
            # Tá»± Ä‘á»™ng reformat file sau khi dá»‹ch xong
            if CAN_REFORMAT:
                print("\nğŸ”§ Báº¯t Ä‘áº§u reformat file Ä‘Ã£ dá»‹ch...")
                try:
                    fix_text_format(output_file)
                    print("âœ… Reformat hoÃ n thÃ nh!")
                except Exception as e:
                    print(f"âš ï¸ Lá»—i khi reformat: {e}")
            else:
                print("âš ï¸ Chá»©c nÄƒng reformat khÃ´ng kháº£ dá»¥ng")
            
            return True
        else:
            print(f"âš ï¸ QuÃ¡ trÃ¬nh dá»‹ch bá»‹ giÃ¡n Ä‘oáº¡n.")
            print(f"ÄÃ£ xá»­ lÃ½ {next_expected_chunk_to_write}/{total_chunks} chunks.")
            print(f"Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ cháº¡y láº¡i chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ tiáº¿p tá»¥c.")
            return False

    except FileNotFoundError:
        print(f"âŒ Lá»—i: KhÃ´ng tÃ¬m tháº¥y file Ä‘áº§u vÃ o '{input_file}'.")
        return False
    except Exception as e:
        print(f"âŒ ÄÃ£ xáº£y ra lá»—i khÃ´ng mong muá»‘n: {e}")
        print("Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u. Báº¡n cÃ³ thá»ƒ cháº¡y láº¡i chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ tiáº¿p tá»¥c.")
        return False


def load_api_key():
    """Tá»± Ä‘á»™ng load API key tá»« environment variable hoáº·c file config"""
    # Thá»­ load tá»« environment variable
    import os
    api_key = os.getenv('GOOGLE_AI_API_KEY')
    if api_key:
        print(f"âœ… ÄÃ£ load API key tá»« environment variable")
        return api_key
    
    # Thá»­ load tá»« file config.json
    try:
        if os.path.exists('config.json'):
            with open('config.json', 'r', encoding='utf-8') as f:
                config = json.load(f)
                api_key = config.get('api_key')
                if api_key:
                    print(f"âœ… ÄÃ£ load API key tá»« config.json")
                    return api_key
    except:
        pass
    
    return None

def main():
    """Interactive main function for command line usage"""
    print("=== TranslateNovelAI - Command Line Version ===\n")
    
    # Thá»­ tá»± Ä‘á»™ng load API Key
    api_key = load_api_key()
    
    if not api_key:
        # Nháº­p API Key manually
        api_key = input("Nháº­p Google AI API Key: ").strip()
        if not api_key:
            print("âŒ API Key khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
            return
        
        # Há»i cÃ³ muá»‘n lÆ°u vÃ o config.json khÃ´ng
        save_key = input("ğŸ’¾ LÆ°u API key vÃ o config.json? (y/N): ").lower().strip()
        if save_key == 'y':
            try:
                config = {'api_key': api_key}
                with open('config.json', 'w', encoding='utf-8') as f:
                    json.dump(config, f, indent=2)
                print("âœ… ÄÃ£ lÆ°u API key vÃ o config.json")
            except Exception as e:
                print(f"âš ï¸ Lá»—i lÆ°u config: {e}")
    else:
        print(f"ğŸ”‘ API Key: {api_key[:10]}***{api_key[-10:]}")
    
    # Nháº­p Ä‘Æ°á»ng dáº«n file input
    input_file = input("Nháº­p Ä‘Æ°á»ng dáº«n file truyá»‡n cáº§n dá»‹ch: ").strip()
    if not input_file:
        print("âŒ ÄÆ°á»ng dáº«n file khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
        return
    
    # Kiá»ƒm tra file tá»“n táº¡i
    if not os.path.exists(input_file):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {input_file}")
        return
    
    # TÃ¹y chá»n file output (cÃ³ thá»ƒ Ä‘á»ƒ trá»‘ng)
    output_file = input("Nháº­p Ä‘Æ°á»ng dáº«n file output (Ä‘á»ƒ trá»‘ng Ä‘á»ƒ tá»± Ä‘á»™ng táº¡o): ").strip()
    if not output_file:
        output_file = None
        print("ğŸ“ Sáº½ tá»± Ä‘á»™ng táº¡o tÃªn file output")
    
    # TÃ¹y chá»n model
    print("\nChá»n model:")
    print("1. gemini-2.0-flash (khuyáº¿n nghá»‹)")
    print("2. gemini-1.5-flash")
    print("3. gemini-1.5-pro")
    
    model_choice = input("Nháº­p lá»±a chá»n (1-3, máº·c Ä‘á»‹nh 1): ").strip()
    model_map = {
        "1": "gemini-2.0-flash",
        "2": "gemini-1.5-flash", 
        "3": "gemini-1.5-pro",
        "": "gemini-2.0-flash"  # Default
    }
    
    model_name = model_map.get(model_choice, "gemini-2.0-flash")
    print(f"ğŸ“± Sá»­ dá»¥ng model: {model_name}")
    
    # XÃ¡c nháº­n trÆ°á»›c khi báº¯t Ä‘áº§u
    print(f"\nğŸ“‹ ThÃ´ng tin dá»‹ch:")
    print(f"  Input: {input_file}")
    print(f"  Output: {output_file or 'Tá»± Ä‘á»™ng táº¡o'}")
    print(f"  Model: {model_name}")
    print(f"  Threads: {get_optimal_threads()}")
    print(f"  Chunk size: {CHUNK_SIZE_LINES} dÃ²ng")
    
    confirm = input("\nğŸš€ Báº¯t Ä‘áº§u dá»‹ch? (y/N): ").lower().strip()
    if confirm != 'y':
        print("âŒ Há»§y bá».")
        return
    
    # Báº¯t Ä‘áº§u dá»‹ch
    print("\n" + "="*50)
    try:
        success = translate_file_optimized(
            input_file=input_file,
            output_file=output_file,
            api_key=api_key,
            model_name=model_name
        )
        
        if success:
            print("\nğŸ‰ Dá»‹ch hoÃ n thÃ nh thÃ nh cÃ´ng!")
        else:
            print("\nâš ï¸ Dá»‹ch chÆ°a hoÃ n thÃ nh.")
            
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ NgÆ°á»i dÃ¹ng dá»«ng chÆ°Æ¡ng trÃ¬nh.")
        print("ğŸ’¾ Tiáº¿n Ä‘á»™ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u, cÃ³ thá»ƒ tiáº¿p tá»¥c sau.")
    except Exception as e:
        print(f"\nâŒ Lá»—i khÃ´ng mong muá»‘n: {e}")


if __name__ == "__main__":
    main()