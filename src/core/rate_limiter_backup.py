#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BACKUP - Rate Limiter cho Google AI API (Original Version)
Gi√∫p tr√°nh v∆∞·ª£t qu√° gi·ªõi h·∫°n RPM (Requests Per Minute) c·ªßa Google AI
"""

import time
import threading
from collections import deque
from datetime import datetime, timedelta


class RateLimiter:
    """
    Rate limiter ƒë∆°n gi·∫£n s·ª≠ d·ª•ng sliding window
    
    Google AI Free Tier Limits:
    - Gemini 2.0 Flash: 10 RPM, 1,500,000 TPM
    - Gemini 1.5 Flash: 15 RPM, 1,000,000 TPM  
    - Gemini 1.5 Pro: 2 RPM, 32,000 TPM
    """
    
    def __init__(self, requests_per_minute=10, window_seconds=60):
        """
        Initialize rate limiter
        
        Args:
            requests_per_minute: S·ªë requests t·ªëi ƒëa m·ªói ph√∫t
            window_seconds: K√≠ch th∆∞·ªõc c·ª≠a s·ªï th·ªùi gian (m·∫∑c ƒë·ªãnh 60s)
        """
        self.max_requests = requests_per_minute
        self.window_seconds = window_seconds
        self.requests = deque()
        self.lock = threading.Lock()
        
    def acquire(self):
        """
        Acquire permission to make a request
        Blocks if rate limit would be exceeded
        """
        with self.lock:
            now = datetime.now()
            
            # X√≥a c√°c requests c≈© ngo√†i window
            cutoff_time = now - timedelta(seconds=self.window_seconds)
            while self.requests and self.requests[0] < cutoff_time:
                self.requests.popleft()
            
            # Ki·ªÉm tra xem c√≥ v∆∞·ª£t qu√° limit kh√¥ng
            if len(self.requests) >= self.max_requests:
                # T√≠nh th·ªùi gian c·∫ßn ch·ªù
                oldest_request = self.requests[0]
                wait_time = (oldest_request + timedelta(seconds=self.window_seconds) - now).total_seconds()
                
                if wait_time > 0:
                    print(f"üö¶ Rate limit: {len(self.requests)}/{self.max_requests} requests. ƒê·ª£i {wait_time:.1f}s...")
                    time.sleep(wait_time + 0.1)  # Th√™m 0.1s buffer
                    
                    # X√≥a l·∫°i c√°c requests c≈© sau khi ƒë·ª£i
                    now = datetime.now()
                    cutoff_time = now - timedelta(seconds=self.window_seconds)
                    while self.requests and self.requests[0] < cutoff_time:
                        self.requests.popleft()
            
            # Th√™m request hi·ªán t·∫°i
            self.requests.append(now)
            current_count = len(self.requests)
            if current_count % 5 == 0:  # Log m·ªói 5 requests
                print(f"üìä Rate limiter: {current_count}/{self.max_requests} requests trong 60s")
    
    def get_current_usage(self):
        """Get current number of requests in the window"""
        with self.lock:
            now = datetime.now()
            cutoff_time = now - timedelta(seconds=self.window_seconds)
            
            # X√≥a c√°c requests c≈©
            while self.requests and self.requests[0] < cutoff_time:
                self.requests.popleft()
            
            return len(self.requests)
    
    def get_wait_time(self):
        """Get time to wait before next request is allowed"""
        with self.lock:
            now = datetime.now()
            cutoff_time = now - timedelta(seconds=self.window_seconds)
            
            # X√≥a c√°c requests c≈©
            while self.requests and self.requests[0] < cutoff_time:
                self.requests.popleft()
            
            if len(self.requests) < self.max_requests:
                return 0
            
            # T√≠nh th·ªùi gian ch·ªù
            oldest_request = self.requests[0]
            wait_time = (oldest_request + timedelta(seconds=self.window_seconds) - now).total_seconds()
            return max(0, wait_time)


# Rate limiters cho c√°c models Google AI kh√°c nhau
# Format: {(model_name, api_key_hash): RateLimiter}
_rate_limiters = {}
_lock = threading.Lock()


def _get_key_hash(api_key: str) -> str:
    """Get a hash of API key for use as dictionary key"""
    import hashlib
    return hashlib.md5(api_key.encode()).hexdigest()[:8]


def get_rate_limiter(model_name: str, provider: str = "Google AI", api_key: str = None) -> RateLimiter:
    """
    Get ho·∫∑c t·∫°o rate limiter cho model (v√† key c·ª• th·ªÉ n·∫øu c√≥)
    
    Args:
        model_name: T√™n model
        provider: Provider (ch·ªâ √°p d·ª•ng cho Google AI)
        api_key: API key (d√πng ƒë·ªÉ t·∫°o rate limiter ri√™ng cho m·ªói key)
        
    Returns:
        RateLimiter instance ho·∫∑c None n·∫øu kh√¥ng c·∫ßn rate limiting
    """
    # Ch·ªâ rate limit cho Google AI
    if provider != "Google AI":
        return None
    
    with _lock:
        # T·∫°o unique key cho rate limiter
        if api_key:
            # M·ªói API key c√≥ rate limiter ri√™ng
            key_hash = _get_key_hash(api_key)
            limiter_key = f"{model_name}_{key_hash}"
        else:
            # Backward compatibility: d√πng model_name l√†m key
            limiter_key = model_name
        
        if limiter_key not in _rate_limiters:
            # X√°c ƒë·ªãnh RPM d·ª±a tr√™n model
            # Free tier limits from: https://ai.google.dev/gemini-api/docs/rate-limits?hl=vi
            rpm = 10  # Default safe value
            
            if "2.0-flash" in model_name.lower() or "2.0flash" in model_name.lower() or "2.0_flash" in model_name.lower():
                rpm = 10
            elif "1.5-flash" in model_name.lower() or "1.5flash" in model_name.lower() or "1.5_flash" in model_name.lower():
                rpm = 15
            elif "1.5-pro" in model_name.lower() or "1.5_pro" in model_name.lower():
                rpm = 2  # Very low!
            elif "pro" in model_name.lower():
                rpm = 2  # Conservative for Pro models
            else:
                rpm = 10  # Default safe value
            
            # Gi·∫£m RPM xu·ªëng 80% ƒë·ªÉ an to√†n h∆°n
            safe_rpm = int(rpm * 0.8)
            if safe_rpm < 1:
                safe_rpm = 1
            
            key_display = f"key_***{key_hash}" if api_key else "default"
            print(f"üîß ƒê√£ t·∫°o rate limiter cho model: {model_name} ({key_display})")
            print(f"   üìä Gi·ªõi h·∫°n g·ªëc: {rpm} RPM")
            print(f"   üõ°Ô∏è Gi·ªõi h·∫°n an to√†n: {safe_rpm} RPM (80% c·ªßa g·ªëc)")
            print(f"   üåê Tham kh·∫£o: https://ai.google.dev/gemini-api/docs/rate-limits")
            
            _rate_limiters[limiter_key] = RateLimiter(requests_per_minute=safe_rpm)
        
        return _rate_limiters[limiter_key]


def clear_rate_limiters():
    """Clear all rate limiters (for testing or reset)"""
    global _rate_limiters
    with _lock:
        _rate_limiters.clear()


# Exponential backoff cho retry khi g·∫∑p rate limit errors
def exponential_backoff_sleep(retry_count: int, base_delay: float = 1.0, max_delay: float = 60.0):
    """
    Sleep v·ªõi exponential backoff
    
    Args:
        retry_count: S·ªë l·∫ßn retry hi·ªán t·∫°i (0-indexed)
        base_delay: Delay c∆° b·∫£n (gi√¢y)
        max_delay: Delay t·ªëi ƒëa (gi√¢y)
    """
    delay = min(base_delay * (2 ** retry_count), max_delay)
    print(f"‚è±Ô∏è Exponential backoff: ƒë·ª£i {delay:.1f}s (retry #{retry_count + 1})")
    time.sleep(delay)


def is_rate_limit_error(error_message: str) -> bool:
    """
    Ki·ªÉm tra xem l·ªói c√≥ ph·∫£i l√† rate limit error kh√¥ng
    
    Args:
        error_message: Th√¥ng b√°o l·ªói
        
    Returns:
        True n·∫øu l√† rate limit error
    """
    error_lower = str(error_message).lower()
    rate_limit_keywords = [
        "rate limit",
        "quota exceeded",
        "429",
        "too many requests",
        "resource exhausted",
        "requests per minute",
        "rpm",
        "rate_limit_exceeded",
        "quota_exceeded",
        "too_many_requests",
        # Google AI specific errors
        "resource has been exhausted",
        "quota_exhausted",
        "rate_limit_error",
        # HTTP status codes
        "status: 429",
        "status code: 429",
        "http 429"
    ]
    
    is_rate_limit = any(keyword in error_lower for keyword in rate_limit_keywords)
    
    if is_rate_limit:
        print(f"üö® Detected rate limit error: {error_message[:100]}...")
    
    return is_rate_limit

